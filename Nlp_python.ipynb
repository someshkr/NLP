{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nlp_python.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgUsJqownqHS",
        "outputId": "bcefe7d7-8e0b-462a-d54e-32a0a1e82b28"
      },
      "source": [
        "!pip install spacy\n",
        "\n",
        "!python -m spacy download en"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (56.1.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (56.1.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCl7VpB_oLeP"
      },
      "source": [
        "**Tokenizing the Text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBba2RS3oHPq",
        "outputId": "e0433c95-9b98-44db-cb4b-5ae3fe11979d"
      },
      "source": [
        "%%time\n",
        "# Word tokenization\n",
        "from spacy.lang.en import English\n",
        "\n",
        "# Load English tokenizer, tagger, parser, NER and word vectors\n",
        "nlp = English()\n",
        "\n",
        "text = \"\"\"When learning data science, you shouldn't get discouraged!\n",
        "Challenges and setbacks aren't failures, they're just part of the journey. You've got this!\"\"\"\n",
        "\n",
        "#  \"nlp\" Object is used to create documents with linguistic annotations.\n",
        "my_doc = nlp(text)\n",
        "\n",
        "# Create list of word tokens\n",
        "token_list = []\n",
        "for token in my_doc:\n",
        "    token_list.append(token.text)\n",
        "print(token_list)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['When', 'learning', 'data', 'science', ',', 'you', 'should', \"n't\", 'get', 'discouraged', '!', '\\n', 'Challenges', 'and', 'setbacks', 'are', \"n't\", 'failures', ',', 'they', \"'re\", 'just', 'part', 'of', 'the', 'journey', '.', 'You', \"'ve\", 'got', 'this', '!']\n",
            "CPU times: user 291 ms, sys: 5.97 ms, total: 297 ms\n",
            "Wall time: 297 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKQ7ADv9otGv",
        "outputId": "f7ec74e8-7c44-4030-c777-ad12176386ba"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64YBJYQqqXyi",
        "outputId": "06f4ca0c-53fb-41d7-85a1-b32a6aeae12c"
      },
      "source": [
        "%%time\n",
        "def Preprocessing_text(text):\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        text = text.lower()\n",
        "        text = re.sub('\\W+',' ', text)\n",
        "        text = nltk.word_tokenize(text) \n",
        "        return text\n",
        "Preprocessing_text(text)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 568 µs, sys: 0 ns, total: 568 µs\n",
            "Wall time: 648 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSpYHCrE5YJt"
      },
      "source": [
        "# Sentence tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8NeyR2z2J5c",
        "outputId": "9eb2d605-4e44-43e9-baa7-de2d6e94e26e"
      },
      "source": [
        "%%time\n",
        "# Create the pipeline 'sentencizer' component\n",
        "sbd = nlp.create_pipe('sentencizer')\n",
        "\n",
        "# Add the component to the pipeline\n",
        "nlp.add_pipe(sbd)\n",
        "\n",
        "doc = nlp(text)\n",
        "sents_list = []\n",
        "for sent in doc.sents:\n",
        "    sents_list.append(sent.text)\n",
        "print(sents_list)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"When learning data science, you shouldn't get discouraged!\", \"\\nChallenges and setbacks aren't failures, they're just part of the journey.\", \"You've got this!\"]\n",
            "CPU times: user 68.4 ms, sys: 338 µs, total: 68.7 ms\n",
            "Wall time: 75.3 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9GyDEhF2i22",
        "outputId": "d09bcd2c-a5b6-4bf0-e289-6ec5d240314a"
      },
      "source": [
        "%%time\n",
        "text = \"\"\"When learning data science, you shouldn't get discouraged!\n",
        "Challenges and setbacks aren't failures, they're just part of the journey. You've got this!\"\"\"\n",
        "def Preprocessing_text(text):\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        text = text.lower()\n",
        "        #text = re.sub('\\W+',' ', text)\n",
        "        text = nltk.sent_tokenize(text) \n",
        "        return text\n",
        "Preprocessing_text(text)\n",
        "\n",
        "print(Preprocessing_text(text))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"when learning data science, you shouldn't get discouraged!\", \"challenges and setbacks aren't failures, they're just part of the journey.\", \"you've got this!\"]\n",
            "CPU times: user 1.63 ms, sys: 0 ns, total: 1.63 ms\n",
            "Wall time: 1.6 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLHjE3XF5SKx"
      },
      "source": [
        "# Cleaning Text Data: Removing *Stopwords* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Trs0EOKpM3YP",
        "outputId": "0dbb89bb-7820-4c17-94be-935c54377ba0"
      },
      "source": [
        "%%time\n",
        "print(stopwords.words('english')[:20])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n",
            "CPU times: user 428 µs, sys: 965 µs, total: 1.39 ms\n",
            "Wall time: 1.58 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFneN3TD5ktB",
        "outputId": "4f653ffa-289a-4fea-a1f3-eb1b62acb0c8"
      },
      "source": [
        "%%time\n",
        "#Stop words\n",
        "#importing stop words from English language.\n",
        "import spacy\n",
        "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
        "\n",
        "#Printing the total number of stop words:\n",
        "print('Number of stop words: %d' % len(spacy_stopwords))\n",
        "\n",
        "#Printing first ten stop words:\n",
        "print('First ten stop words: %s' % list(spacy_stopwords)[:20])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of stop words: 326\n",
            "First ten stop words: ['myself', 'too', '‘ll', 'keep', 'they', 'hereafter', 'third', 'namely', 'meanwhile', 'your', 'her', 'seem', 'during', 'none', 'she', 'being', 'own', 'moreover', 'now', 'twenty']\n",
            "CPU times: user 1.48 ms, sys: 0 ns, total: 1.48 ms\n",
            "Wall time: 1.63 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UvD-uhP5wRv",
        "outputId": "5446ddd6-52d2-47a6-9edc-10019c58ab89"
      },
      "source": [
        "%%time\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "text = \"\"\"When learning data science, you shouldn't get discouraged!\n",
        "Challenges and setbacks aren't failures, they're just part of the journey. You've got this!\"\"\"\n",
        "\n",
        "#Implementation of stop words:\n",
        "filtered_sent=[]\n",
        "\n",
        "#  \"nlp\" Object is used to create documents with linguistic annotations.\n",
        "doc = nlp(text)\n",
        "\n",
        "# filtering stop words\n",
        "for word in doc:\n",
        "    \n",
        "    if word.is_stop==False:\n",
        "        filtered_sent.append(word)\n",
        "print(\"Filtered Sentence:\",filtered_sent)\n",
        "\n",
        "#[word for word in doc if word.is_stop==False]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filtered Sentence: [learning, data, science, ,, discouraged, !, \n",
            ", Challenges, setbacks, failures, ,, journey, ., got, !]\n",
            "CPU times: user 60.3 ms, sys: 363 µs, total: 60.7 ms\n",
            "Wall time: 64.1 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-GOWDpUNmNh",
        "outputId": "1e9f3ecd-f788-4dd8-8cc0-bbbe34f24ff1"
      },
      "source": [
        "%%time\n",
        "text = \"\"\"When learning data science, you shouldn't get discouraged!\n",
        "Challenges and setbacks aren't failures, they're just part of the journey. You've got this!\"\"\"\n",
        "\n",
        "def Preprocessing_text(text):\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        text = text.lower()\n",
        "        text = re.sub('\\W+',' ', text)\n",
        "        text = nltk.word_tokenize(text)    \n",
        "        text = [lemmatizer.lemmatize(word) for word in text if word not in set(stopwords.words('english'))]   \n",
        "        return text\n",
        "print(Preprocessing_text(text))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['learning', 'data', 'science', 'get', 'discouraged', 'challenge', 'setback', 'failure', 'part', 'journey', 'got']\n",
            "CPU times: user 8.8 ms, sys: 51 µs, total: 8.85 ms\n",
            "Wall time: 8.95 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0CF28bq5_AJ"
      },
      "source": [
        "# Lexicon Normalization\n",
        "Lexicon normalization is another step in the text data cleaning process. In the big picture, normalization converts high dimensional features into low dimensional features which are appropriate for any machine learning model. For our purposes here, we’re only going to look at lemmatization, a way of processing words that reduces them to their roots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7_rX8sR5-eg",
        "outputId": "1d3b46bb-b381-4a63-953a-70f7f4a5f04d"
      },
      "source": [
        "%%time\n",
        "# Implementing lemmatization\n",
        "text = \"\"\"When learning data science, you shouldn't get discouraged!\n",
        "Challenges and setbacks aren't failures, they're just part of the journey. You've got this!\"\"\"\n",
        "text = re.sub('\\W+',' ', text)\n",
        "lem = nlp(text)\n",
        "# finding lemma for each word\n",
        "for word in lem:\n",
        "    print(word.text,word.lemma_)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "When When\n",
            "learning learning\n",
            "data data\n",
            "science science\n",
            "you you\n",
            "shouldn shouldn\n",
            "t t\n",
            "get get\n",
            "discouraged discouraged\n",
            "Challenges Challenges\n",
            "and and\n",
            "setbacks setbacks\n",
            "aren aren\n",
            "t t\n",
            "failures failures\n",
            "they they\n",
            "re re\n",
            "just just\n",
            "part part\n",
            "of of\n",
            "the the\n",
            "journey journey\n",
            "You You\n",
            "ve ve\n",
            "got got\n",
            "this this\n",
            "CPU times: user 76.3 ms, sys: 1.85 ms, total: 78.2 ms\n",
            "Wall time: 76.3 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "croCSttjW1hI"
      },
      "source": [
        "# **POS TAGGING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9lcmP0gHol2",
        "outputId": "f554c8d6-0240-4f78-d72f-ee3e594be5ba"
      },
      "source": [
        "%%time\n",
        "\n",
        "# POS tagging\n",
        "\n",
        "# importing the model en_core_web_sm of English for vocabluary, syntax & entities\n",
        "import en_core_web_sm\n",
        "\n",
        "# load en_core_web_sm of English for vocabluary, syntax & entities\n",
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "#  \"nlp\" Objectis used to create documents with linguistic annotations.\n",
        "docs = nlp(u\"All is well that ends well.\")\n",
        "\n",
        "for word in docs:\n",
        "    print(word.text,word.pos_)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All DET\n",
            "is AUX\n",
            "well ADJ\n",
            "that DET\n",
            "ends VERB\n",
            "well ADV\n",
            ". PUNCT\n",
            "CPU times: user 750 ms, sys: 48.9 ms, total: 799 ms\n",
            "Wall time: 797 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AF6dDSteIFPQ",
        "outputId": "25e1ae27-b883-431d-e716-cd1a392e0a13"
      },
      "source": [
        "from nltk import pos_tag\n",
        "from nltk import RegexpParser\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7yrVlRjIQqf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37861e60-0d7e-45e4-a4d7-ccca65009ca4"
      },
      "source": [
        "%%time\n",
        "text =\"learn php from guru99 and make study easy\".split()\n",
        "print(\"After Split:\",text)\n",
        "tokens_tag = pos_tag(text)\n",
        "print(\"After Token:\",tokens_tag)\n",
        "patterns= \"\"\"mychunk:{<NN.?>*<VBD.?>*<JJ.?>*<CC>?}\"\"\"\n",
        "chunker = RegexpParser(patterns)\n",
        "print(\"After Regex:\",chunker)\n",
        "output = chunker.parse(tokens_tag)\n",
        "print(\"After Chunking\",output)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After Split: ['learn', 'php', 'from', 'guru99', 'and', 'make', 'study', 'easy']\n",
            "After Token: [('learn', 'JJ'), ('php', 'NN'), ('from', 'IN'), ('guru99', 'NN'), ('and', 'CC'), ('make', 'VB'), ('study', 'NN'), ('easy', 'JJ')]\n",
            "After Regex: chunk.RegexpParser with 1 stages:\n",
            "RegexpChunkParser with 1 rules:\n",
            "       <ChunkRule: '<NN.?>*<VBD.?>*<JJ.?>*<CC>?'>\n",
            "After Chunking (S\n",
            "  (mychunk learn/JJ)\n",
            "  (mychunk php/NN)\n",
            "  from/IN\n",
            "  (mychunk guru99/NN and/CC)\n",
            "  make/VB\n",
            "  (mychunk study/NN easy/JJ))\n",
            "CPU times: user 6.58 ms, sys: 1.09 ms, total: 7.67 ms\n",
            "Wall time: 7.45 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEcrhIboW72F"
      },
      "source": [
        "# **Entity Detection**\n",
        "Entity detection, also called entity recognition, is a more advanced form of language processing that identifies important elements like places, people, organizations, and languages within an input string of text. This is really helpful for quickly extracting information from text, since you can quickly pick out important topics or indentify key sections of text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2386m-0W7DE",
        "outputId": "729a7f39-7516-4cd8-b897-c6041e695c4b"
      },
      "source": [
        "%%time\n",
        "from spacy import displacy\n",
        "\n",
        "nytimes= nlp(u\"\"\"New York City on Tuesday declared a public health emergency and ordered mandatory measles vaccinations amid an outbreak, becoming the latest national flash point over refusals to inoculate against dangerous diseases.\n",
        "\n",
        "At least 285 people have contracted measles in the city since September, mostly in Brooklyn’s Williamsburg neighborhood. The order covers four Zip codes there, Mayor Bill de Blasio (D) said Tuesday.\n",
        "\n",
        "The mandate orders all unvaccinated people in the area, including a concentration of Orthodox Jews, to receive inoculations, including for children as young as 6 months old. Anyone who resists could be fined up to $1,000.\"\"\")\n",
        "\n",
        "entities=[(i, i.label_, i.label) for i in nytimes.ents]\n",
        "print(entities)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(New York City, 'GPE', 384), (Tuesday, 'DATE', 391), (At least 285, 'CARDINAL', 397), (September, 'DATE', 391), (Brooklyn, 'GPE', 384), (Williamsburg, 'GPE', 384), (four, 'CARDINAL', 397), (Bill de Blasio, 'PERSON', 380), (Tuesday, 'DATE', 391), (Orthodox Jews, 'PERSON', 380), (6 months old, 'DATE', 391), (up to $1,000, 'MONEY', 394)]\n",
            "CPU times: user 98.8 ms, sys: 0 ns, total: 98.8 ms\n",
            "Wall time: 102 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "0u4moyT4XMzI",
        "outputId": "cb1badae-9e6e-468d-cc58-1958626bbe66"
      },
      "source": [
        "%%time\n",
        "displacy.render(nytimes, style = \"ent\",jupyter = True)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    New York City\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Tuesday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " declared a public health emergency and ordered mandatory measles vaccinations amid an outbreak, becoming the latest national flash point over refusals to inoculate against dangerous diseases.</br></br>\n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    At least 285\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " people have contracted measles in the city since \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    September\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ", mostly in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Brooklyn\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              "’s \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Williamsburg\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " neighborhood. The order covers \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    four\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " Zip codes there, Mayor \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bill de Blasio\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " (D) said \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Tuesday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ".</br></br>The mandate orders all unvaccinated people in the area, including a concentration of \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Orthodox Jews\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", to receive inoculations, including for children as young as \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    6 months old\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ". Anyone who resists could be fined \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    up to $1,000\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              ".</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 131 ms, sys: 1.36 ms, total: 132 ms\n",
            "Wall time: 136 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrRTYXGwYg83",
        "outputId": "963146fc-e5bb-48d0-ce1b-03664320b4a0"
      },
      "source": [
        " nltk.download('maxent_ne_chunker')\n",
        " nltk.download('words')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B9rFvEdXflw",
        "outputId": "bba62fe4-12c1-4b52-8015-21ba72a25da2"
      },
      "source": [
        "%%time\n",
        "sentence='New York City on Tuesday declared a public health emergency and ordered mandatory measles vaccinations amid an outbreak, becoming the latest national flash point over refusals to inoculate against dangerous diseases.At least 285 people have contracted measles in the city since September, mostly in Brooklyn’s Williamsburg neighborhood. The order covers four Zip codes there, Mayor Bill de Blasio (D) said Tuesday.The mandate orders all unvaccinated people in the area, including a concentration of Orthodox Jews, to receive inoculations, including for children as young as 6 months old. Anyone who resists could be fined up to $1,000.'\n",
        " \n",
        "for sent in nltk.sent_tokenize(sentence):\n",
        "   for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
        "      if hasattr(chunk, 'label'):\n",
        "         print(chunk.label(), ' '.join(c[0] for c in chunk))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPE New York City\n",
            "GPE Brooklyn\n",
            "PERSON Williamsburg\n",
            "PERSON Mayor Bill\n",
            "GPE Blasio\n",
            "ORGANIZATION Orthodox Jews\n",
            "CPU times: user 57.1 ms, sys: 2.8 ms, total: 59.9 ms\n",
            "Wall time: 59 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EAErmLzfpaf"
      },
      "source": [
        "# **Dependency Parsing**\n",
        "Depenency parsing is a language processing technique that allows us to better determine the meaning of a sentence by analyzing how it’s constructed to determine how the individual words relate to each other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kt-HtCZJgTXe",
        "outputId": "d70764f9-9817-4dea-c4db-a76774314a75"
      },
      "source": [
        "docp = nlp (\" In pursuit of a wall, President Trump ran into one.\")\n",
        "\n",
        "for chunk in docp.noun_chunks:\n",
        "   print(chunk.text, chunk.root.text, chunk.root.dep_,\n",
        "          chunk.root.head.text)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pursuit pursuit pobj In\n",
            "a wall wall pobj of\n",
            "President Trump Trump nsubj ran\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "UGl27GEtgi2r",
        "outputId": "4c7640ef-a0f9-4aa5-fa57-e7fdd4270273"
      },
      "source": [
        "displacy.render(docp, style=\"dep\", jupyter= True)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"5a7c67b680234381bda8024ce57aec9c-0\" class=\"displacy\" width=\"1975\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\"> </tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">SPACE</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">In</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">pursuit</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">of</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">wall,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">President</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">Trump</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">ran</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">into</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">one.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-5a7c67b680234381bda8024ce57aec9c-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-5a7c67b680234381bda8024ce57aec9c-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"></textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-5a7c67b680234381bda8024ce57aec9c-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,2.0 1450.0,2.0 1450.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-5a7c67b680234381bda8024ce57aec9c-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-5a7c67b680234381bda8024ce57aec9c-0-2\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-5a7c67b680234381bda8024ce57aec9c-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M390.0,266.5 L398.0,254.5 382.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-5a7c67b680234381bda8024ce57aec9c-0-3\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-5a7c67b680234381bda8024ce57aec9c-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M565.0,266.5 L573.0,254.5 557.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-5a7c67b680234381bda8024ce57aec9c-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-5a7c67b680234381bda8024ce57aec9c-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-5a7c67b680234381bda8024ce57aec9c-0-5\" stroke-width=\"2px\" d=\"M595,264.5 C595,89.5 920.0,89.5 920.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-5a7c67b680234381bda8024ce57aec9c-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M920.0,266.5 L928.0,254.5 912.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-5a7c67b680234381bda8024ce57aec9c-0-6\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-5a7c67b680234381bda8024ce57aec9c-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-5a7c67b680234381bda8024ce57aec9c-0-7\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,177.0 1440.0,177.0 1440.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-5a7c67b680234381bda8024ce57aec9c-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1295,266.5 L1287,254.5 1303,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-5a7c67b680234381bda8024ce57aec9c-0-8\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,177.0 1615.0,177.0 1615.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-5a7c67b680234381bda8024ce57aec9c-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1615.0,266.5 L1623.0,254.5 1607.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-5a7c67b680234381bda8024ce57aec9c-0-9\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,177.0 1790.0,177.0 1790.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-5a7c67b680234381bda8024ce57aec9c-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1790.0,266.5 L1798.0,254.5 1782.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0WtjTu5hWIL"
      },
      "source": [
        "# **Word Vector Representation**\n",
        "When we’re looking at words alone, it’s difficult for a machine to understand connections that a human would understand immediately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0OIIKz1hVF3",
        "outputId": "23d82dbb-41b5-478f-a91f-d60cd9dfd68d"
      },
      "source": [
        "%%time\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "mango = nlp(u'mango')\n",
        "print(mango.vector.shape)\n",
        "print(mango.vector)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(96,)\n",
            "[ 0.20538223 -1.6033714   0.27122334  0.4102599   3.2985601   3.4889512\n",
            "  1.8090308  -2.1398475   2.31565     1.5809067   4.1519527  -1.0185633\n",
            " -0.0325011  -2.7471437  -0.4177467  -2.4292274  -0.6153387   2.4422317\n",
            "  0.8078671  -2.4846377   2.0988142   1.4448209  -0.552992   -1.3411183\n",
            " -0.69847786 -0.45548356  3.8267968  -4.0225782   0.81215733  0.3766132\n",
            "  0.15751392 -1.1428392  -1.3328214   0.7187766   2.1567593  -3.018766\n",
            "  3.4919028   0.6938907  -1.1943094  -0.10796624  4.7029977   3.551554\n",
            " -0.71505725 -4.4580555  -0.26480573  0.6314918  -0.538128   -1.1131921\n",
            " -1.1251849   0.5740081  -1.1976193  -3.5157654   0.425157   -1.7545594\n",
            " -3.058784    0.01680815  0.97784567  1.7633746   0.4561966   2.5090182\n",
            "  0.35267782  0.8351371  -1.394351    0.5082075   0.75960976 -3.3654122\n",
            "  2.3440146  -2.4311178   1.2401564  -1.4498216  -2.3708577   1.274456\n",
            "  2.6584334   2.505236    0.24999112  0.45838034  0.7396465  -3.0134087\n",
            " -1.1449497   2.441533    0.58746856 -0.47240722 -0.99527466 -2.6816308\n",
            "  0.09063269  6.415723   -2.0405467   0.45456767 -1.6633052  -0.92034495\n",
            "  0.12515879 -1.3880293  -2.1336856   2.3337066  -0.68828297 -1.3300103 ]\n",
            "CPU times: user 724 ms, sys: 48.7 ms, total: 773 ms\n",
            "Wall time: 775 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcbuLb8I947o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}